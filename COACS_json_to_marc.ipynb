{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map from IANA 2-character language codes to ISO639-2 3-character language codes, as used in MARC\n",
    "\n",
    "lang_map = {\n",
    "    \"af\": \"afr\",\n",
    "    \"an\": \"arg\",\n",
    "    \"ar\": \"ara\",\n",
    "    \"az\": \"aze\",\n",
    "    \"be\": \"bel\",\n",
    "    \"bg\": \"bul\",\n",
    "    \"br\": \"bre\",\n",
    "    \"bs\": \"bos\",\n",
    "    \"ca\": \"cat\",\n",
    "    \"cs\": \"cze\",\n",
    "    \"cy\": \"wel\",\n",
    "    \"da\": \"dan\",\n",
    "    \"de\": \"ger\",\n",
    "    \"el\": \"gre\",\n",
    "    \"en\": \"eng\",\n",
    "    \"eo\": \"epo\",\n",
    "    \"es\": \"spa\",\n",
    "    \"et\": \"est\",\n",
    "    \"eu\": \"baq\",\n",
    "    \"fa\": \"per\",\n",
    "    \"fi\": \"fin\",\n",
    "    \"fo\": \"fao\",\n",
    "    \"fr\": \"fre\",\n",
    "    \"gl\": \"glg\",\n",
    "    \"he\": \"heb\",\n",
    "    \"hr\": \"hrv\",\n",
    "    \"hu\": \"hun\",\n",
    "    \"id\": \"ind\",\n",
    "    \"it\": \"ita\",\n",
    "    \"ja\": \"jpn\",\n",
    "    \"jv\": \"jav\",\n",
    "    \"ka\": \"geo\",\n",
    "    \"ko\": \"kor\",\n",
    "    \"ku\": \"kur\",\n",
    "    \"ky\": \"kir\",\n",
    "    \"la\": \"lat\",\n",
    "    \"lb\": \"ltz\",\n",
    "    \"lo\": \"lao\",\n",
    "    \"lt\": \"lit\",\n",
    "    \"lv\": \"lav\",\n",
    "    \"mg\": \"mlg\",\n",
    "    \"mk\": \"mac\",\n",
    "    \"mr\": \"mar\",\n",
    "    \"mt\": \"mlt\",\n",
    "    \"nl\": \"dut\",\n",
    "    \"no\": \"nno\",\n",
    "    \"oc\": \"oci\",\n",
    "    \"pl\": \"pol\",\n",
    "    \"pt\": \"por\",\n",
    "    \"ro\": \"rum\",\n",
    "    \"ru\": \"rus\",\n",
    "    \"sk\": \"slo\",\n",
    "    \"sl\": \"slv\",\n",
    "    \"sr\": \"srp\",\n",
    "    \"sv\": \"swe\",\n",
    "    \"sw\": \"swa\",\n",
    "    \"tl\": \"tgl\",\n",
    "    \"tr\": \"tur\",\n",
    "    \"uk\": \"ukr\",\n",
    "    \"ur\": \"urd\",\n",
    "    \"vi\": \"vie\",\n",
    "    \"wa\": \"wln\",\n",
    "    \"zh\": \"chi\"\n",
    "}   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# extract relevant bibliographic information from the AWOL index json dump \n",
    "# and produce marc files for use in library catalogues  \n",
    "\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "from pymarc import Record, Field\n",
    "from pymarc import MARCReader\n",
    "\n",
    "#open multiple files from Input directory  - change according to your system\n",
    "#infiles = glob.glob(\"Input/*.json\")\n",
    "infiles = !find /Users/simonastoyanova/Desktop/awol-json -name '*.json'\n",
    "\n",
    "def create_subordinate_records(parent_record, subordinate_data_list):\n",
    "    '''If a journal record includes a list of individual issues or volumes,\\\n",
    "    this function creates separate marc files for each of those issues or volumes. The journal title and url\\\n",
    "    are taken from the parent record (the journal record) and kept in the subordinate records.'''\n",
    "    result_list = []\n",
    "\n",
    "    for subordinate_resource in subordinate_data_list:\n",
    "        sub_record = Record(force_utf8=True)\n",
    "\n",
    "        # add fields 006, 007 and 008 with minimal physical information to every marc file\n",
    "        if 'title_full' in subordinate_resource:\n",
    "            sub_record.add_field(\n",
    "                Field(\n",
    "                    tag = '006',\n",
    "                    data = \"m\"))   \n",
    "            sub_record.add_field(\n",
    "                Field(\n",
    "                    tag = '007',\n",
    "                    data = \"cr\"))\n",
    "            \n",
    "            # the iana language code from the json file is taken, checked against the list of language codes,\n",
    "            # substituted with its iso639-2 equivalent and put in position 21-24 of the field 008 content\n",
    "            field008val = \"            o       0eng d\" # DEFAULT ENG\n",
    "            if 'languages' in parent_record and parent_record['languages'] is not None:\n",
    "                field008val = field008val[0:21] + lang_map.get(parent_record['languages'][0], \"   \") + field008val[24:]\n",
    "                \n",
    "            sub_record.add_field(\n",
    "                Field(\n",
    "                    tag = '008',\n",
    "                    data = field008val))\n",
    "            \n",
    "    \n",
    "            sub_record.add_field(\n",
    "                Field(\n",
    "                    tag='245',\n",
    "                    indicators=['0', '0'],\n",
    "                    subfields=['a', subordinate_resource['title_full'][:9000]]\n",
    "                    )\n",
    "            )\n",
    "            sub_record.add_field(\n",
    "                Field(\n",
    "                    tag='506',\n",
    "                    indicators=['0', '#'],\n",
    "                    subfields=[\"a\", \"Open access\"])\n",
    "            )\n",
    "\n",
    "        if parent_record['246']['a']:\n",
    "            sub_record.add_field(\n",
    "                Field(\n",
    "                    tag='490',\n",
    "                    indicators=['0', '0'],\n",
    "                    subfields=['a', parent_record['246']['a']])\n",
    "            )\n",
    "\n",
    "        \n",
    "        # put together the issue/volume url, the journal url and the domain in field 856; \n",
    "        # domain and journal url taken from the parent record, issue/volume url taken from the subordinate record\n",
    "        if 'url' in subordinate_resource:\n",
    "            current_field = Field(\n",
    "                tag='856',\n",
    "                indicators=['0', '0']\n",
    "            )\n",
    "\n",
    "            current_field.add_subfield('u', subordinate_resource['url'])\n",
    "\n",
    "            if parent_record['856']['a']:\n",
    "                current_field.add_subfield('a', parent_record['856']['a'])\n",
    "\n",
    "            if parent_record['856']['u']:\n",
    "                current_field.add_subfield('d', parent_record['856']['u'])\n",
    "\n",
    "            sub_record.add_field(\n",
    "                current_field\n",
    "            )\n",
    "\n",
    "        result_list.append(sub_record)\n",
    "\n",
    "    return result_list\n",
    "\n",
    "\n",
    "# marc fields for each journal record\n",
    "\n",
    "for file in infiles:\n",
    "    print('Processing: ' + file)  #progress message\n",
    "    data = json.load(open(file)) \n",
    "    record = Record(force_utf8=True)   #create MARC record, enforce Unicode \n",
    "    \n",
    "    # add fields 006, 007 and 008 with minimal physical information to every marc file\n",
    "    record.add_field(\n",
    "        Field(\n",
    "            tag = '006',\n",
    "            data = \"m\"))   \n",
    "    record.add_field(\n",
    "        Field(\n",
    "            tag = '007',\n",
    "            data = \"cr\"))\n",
    "    \n",
    "    # the iana language code from the json file is taken, checked against the list of language codes,\n",
    "    # substituted with its iso639-2 equivalent and put in position 21-24 of the field 008 content\n",
    "    field008val = \"            o       0eng d\" # DEFAULT ENG\n",
    "    try:\n",
    "        if 'languages' in data and data['languages'][0] is not None:\n",
    "            field008val = field008val[0:21] + lang_map.get(data['languages'][0], \"   \") + field008val[24:]\n",
    "    except IndexError:\n",
    "        field008val = field008val[0:21] + \"   \" + field008val[24:]\n",
    "        \n",
    "                \n",
    "    record.add_field(\n",
    "        Field(\n",
    "            tag = '008',\n",
    "            data = field008val))\n",
    "\n",
    "        \n",
    "    \n",
    "    # extract issn, in json 'generic' and/or 'electronic', and put into separate subfields of 022\n",
    "    \n",
    "    if \"identifiers\" in data and \"issn\" in data[\"identifiers\"]:\n",
    "        field_issn = Field(\n",
    "                tag='022',\n",
    "                indicators=['0', '#']\n",
    "        )\n",
    "        \n",
    "        if \"generic\" in data[\"identifiers\"][\"issn\"]:\n",
    "            field_issn.add_subfield('a', data[\"identifiers\"][\"issn\"][\"generic\"][0])\n",
    "            \n",
    "        if \"electronic\" in data[\"identifiers\"][\"issn\"]:\n",
    "            field_issn.add_subfield('l', data[\"identifiers\"][\"issn\"][\"electronic\"][0])\n",
    "            \n",
    "        record.add_field(field_issn)\n",
    "    \n",
    "\n",
    "            \n",
    "        \n",
    "    # title of the series or journal\n",
    "    if data[\"is_part_of\"] is not None and data[\"is_part_of\"]['title_full']:\n",
    "            record.add_field(\n",
    "                Field(\n",
    "                    tag = '245',\n",
    "                    indicators=['0', '0'],\n",
    "                    subfields=[\"a\", data[\"is_part_of\"][\"title_full\"][:9000]]))\n",
    "    if data[\"title\"]:\n",
    "        record.add_field(\n",
    "            Field(\n",
    "                tag='246',\n",
    "                indicators=['0', '0'],\n",
    "                subfields=[\"a\", data[\"title\"][:9000]])\n",
    "        )\n",
    "    \n",
    "    if data[\"year\"]:\n",
    "        record.add_field(\n",
    "            Field(\n",
    "                tag=\"260\",\n",
    "                indicators=[\"#\", \"#\"],\n",
    "                subfields=[\"c\", data[\"year\"]]))\n",
    "     \n",
    "    # add field 506 to all records, as not present in all json files\n",
    "    record.add_field(\n",
    "        Field(\n",
    "            tag='506',\n",
    "            indicators=['0', '#'],\n",
    "            subfields=[\"a\", \"Open access\"])\n",
    "    )\n",
    "    \n",
    "    # some json files contain a very long description; the maximum length of data in a variable field \n",
    "    #in MARC21 is 9,999 bytes, so here only a certain amount of content is put into the 520 field\n",
    "    if data[\"description\"]:\n",
    "        record.add_field(\n",
    "            Field(\n",
    "                tag='520',\n",
    "                indicators=['2', '#'],\n",
    "                subfields=[\"a\", data[\"description\"][:9000]])\n",
    "        )\n",
    "\n",
    "                    \n",
    "        \n",
    "    \n",
    "    # keep together the journal url, host and domain as different subfields of field 856 \n",
    "    # check if either exists, before initializing a new field instance\n",
    "    if data['url'] or (data['is_part_of'] is not None and data['is_part_of']['url']):\n",
    "        field = Field(\n",
    "                tag='856',\n",
    "                indicators=['0', '0']\n",
    "        )\n",
    "        if data['domain']:\n",
    "            field.add_subfield('a', data['domain'])\n",
    "\n",
    "        if data['is_part_of'] is not None and data['is_part_of']['url']:\n",
    "            field.add_subfield('d', data['is_part_of']['url'])\n",
    "\n",
    "        if data['url']:\n",
    "            field.add_subfield('u',  data['url'])\n",
    "        \n",
    "\n",
    "        record.add_field(field)\n",
    "        \n",
    "    if data[\"volume\"]:\n",
    "        record.add_field(\n",
    "            Field(\n",
    "                tag='866',\n",
    "                indicators=['0', '0'],\n",
    "                subfields=[\"a\", data[\"volume\"]]))\n",
    "        \n",
    "    \n",
    "    \n",
    "    slash = file.rfind(\"/\")   #keep filename when creating the marc files\n",
    "    dot = file.rfind(\".\")\n",
    "    \n",
    "    # execute function for creating separate records for subordinate resources\n",
    "    if data['subordinate_resources'] is not None: \n",
    "        subordinate_records = create_subordinate_records(record, data['subordinate_resources'])\n",
    "\n",
    "        counter = 0\n",
    "        \n",
    "        # add counter and \"-sub\" to filenames of subordinate records\n",
    "        for subordinate_record in subordinate_records:\n",
    "            out = open('Output/'+file[slash+1:dot]+'-sub'+str(counter)+'.marc', 'wb')\n",
    "            out.write(subordinate_record.as_marc())\n",
    "            out.close()\n",
    "\n",
    "            counter = counter + 1\n",
    "\n",
    "    #output marc file with same filename in Output directory\n",
    "    out = open('Output/'+file[slash+1:dot]+'.marc', 'wb') \n",
    "    out.write(record.as_marc())\n",
    "    out.close()\n",
    "\n",
    "%time #calculate time of operation\n",
    "\n",
    "\n",
    "#for all marc files in Output folder\n",
    "outfiles = glob.glob(\"Output/*.marc\")\n",
    "\n",
    "#print all new files with their filenames\n",
    "for marc in outfiles:\n",
    "    print(marc)\n",
    "    with open(marc, 'rb') as f:\n",
    "        reader = MARCReader(f)\n",
    "        record = next(reader)\n",
    "        record.as_dict()\n",
    "        print(record)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
